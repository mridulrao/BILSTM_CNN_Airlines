{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b4869f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a902806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = pd.read_csv(\"Airline-Sentiment-2-w-AA.csv\", encoding='ISO-8859–1')\n",
    "tweets = d2['text']\n",
    "sentiment = d2['airline_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08766d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "special_char = ['!', '#', '%', '\"', '&', '*', '(', ')', ';', 'ûï', '\\x89ûï:', '\\x89û\\x9d']\n",
    "\n",
    "def process_tweet(tweet, special_char):\n",
    "    for char in special_char:\n",
    "        tweet = tweet.replace(char, \"\")\n",
    "        \n",
    "    urls = re.findall('http://\\S+|https://\\S+', tweet)\n",
    "    airline_tags = re.findall('@\\w+', tweet)\n",
    "    \n",
    "    for tag in airline_tags:\n",
    "        tweet = tweet.replace(tag, \"\")\n",
    "        \n",
    "    for url in urls:\n",
    "        tweet = tweet.replace(url, \"\")\n",
    "\n",
    "        \n",
    "    return tweet.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1608815",
   "metadata": {},
   "outputs": [],
   "source": [
    "procesed_tweets = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    _tweet = process_tweet(tweet, special_char=special_char)\n",
    "    procesed_tweets.append(_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5140460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sentiment = []\n",
    "\n",
    "for sent in sentiment:\n",
    "    if sent == 'neutral':\n",
    "        processed_sentiment.append('Pos')\n",
    "    elif sent == 'positive':\n",
    "        processed_sentiment.append('Pos')\n",
    "    else:\n",
    "        processed_sentiment.append('Neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54189709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(columns = [\"Review\", \"Sentiment\"])\n",
    "\n",
    "for i in range(len(procesed_tweets)):\n",
    "    row = pd.Series({'Review' : procesed_tweets[i], 'Sentiment' : processed_sentiment[i]})\n",
    "    df_2 = pd.concat([df_2, row.to_frame().T], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6609cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = df_2['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec95f78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:07, 53140.96it/s]\n"
     ]
    }
   ],
   "source": [
    "#import glove embeddings \n",
    "from tqdm import tqdm\n",
    "embedding_vector = {}\n",
    "f = open('glove.6B.200d.txt')\n",
    "for line in tqdm(f):\n",
    "    value = line.split(' ')\n",
    "    word = value[0]\n",
    "    coef = np.array(value[1:],dtype = 'float32')\n",
    "    embedding_vector[word] = coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c32609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee666bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c1d7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df_2, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74651cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = list(train['Review'])\n",
    "y_train = train['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76077f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13777\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(token.word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "054f8ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "seq = token.texts_to_sequences(x_train)\n",
    "pad_seq = pad_sequences(seq, maxlen=1100, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cedd6079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 13776/13776 [00:00<00:00, 151943.40it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "embedding_matrix = np.zeros((vocab_size,200))\n",
    "for word,i in tqdm(token.word_index.items()):\n",
    "    embedding_value = embedding_vector.get(word)\n",
    "    if embedding_value is not None:\n",
    "        embedding_matrix[i] = embedding_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62dd352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert positive-negative to 1-0\n",
    "sentiment = {\n",
    "    \"Pos\" : 0,\n",
    "    \"Neg\" : 1\n",
    "}\n",
    "\n",
    "y_filtered_converted = []\n",
    "for sent in y_train:\n",
    "    y_filtered_converted.append(sentiment[sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7ac60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_filtered_converted = np.int64(y_filtered_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66d02a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Dropout,Embedding,Bidirectional, Conv1D, Flatten, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d4e480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13270836",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Embedding(vocab_size, 200, weights = [embedding_matrix], input_length = 1100, trainable = False))\n",
    "\n",
    "model_1.add(Conv1D(256, 3, activation='tanh', padding = 'same'))\n",
    "model_1.add(Conv1D(128, 3, activation='tanh', padding = 'same'))\n",
    "\n",
    "model_1.add(MaxPooling1D(pool_size = 3, strides = 2, padding = 'same'))\n",
    "\n",
    "model_1.add(Dropout(0.2))\n",
    "\n",
    "model_1.add(Bidirectional(LSTM(256, return_sequences = True)))\n",
    "model_1.add(Bidirectional(LSTM(256, return_sequences = True, kernel_regularizer = keras.regularizers.L2(1e-4))))\n",
    "model_1.add(Bidirectional(LSTM(128)))\n",
    "\n",
    "model_1.add(Dense(10, activation = 'relu'))\n",
    "\n",
    "model_1.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "model_1.compile(optimizer='adam',loss='binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b8a6d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 1100, 200)         2755400   \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 1100, 256)         153856    \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 1100, 128)         98432     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 550, 128)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 550, 128)          0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 550, 512)         788480    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 550, 512)         1574912   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 256)              656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                2570      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,030,045\n",
      "Trainable params: 3,274,645\n",
      "Non-trainable params: 2,755,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10e06545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 12:28:21.759245: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "83/83 [==============================] - 812s 10s/step - loss: 0.5837 - accuracy: 0.7475 - val_loss: 0.4761 - val_accuracy: 0.7883\n",
      "Epoch 2/8\n",
      "83/83 [==============================] - 823s 10s/step - loss: 0.4453 - accuracy: 0.8126 - val_loss: 0.4458 - val_accuracy: 0.8065\n",
      "Epoch 3/8\n",
      "83/83 [==============================] - 843s 10s/step - loss: 0.3754 - accuracy: 0.8446 - val_loss: 0.4439 - val_accuracy: 0.7906\n",
      "Epoch 4/8\n",
      "83/83 [==============================] - 850s 10s/step - loss: 0.3295 - accuracy: 0.8682 - val_loss: 0.4330 - val_accuracy: 0.8156\n",
      "Epoch 5/8\n",
      "83/83 [==============================] - 861s 10s/step - loss: 0.2775 - accuracy: 0.8891 - val_loss: 0.4626 - val_accuracy: 0.8281\n",
      "Epoch 6/8\n",
      "83/83 [==============================] - 855s 10s/step - loss: 0.2226 - accuracy: 0.9166 - val_loss: 0.4836 - val_accuracy: 0.8206\n",
      "Epoch 7/8\n",
      "83/83 [==============================] - 857s 10s/step - loss: 0.1896 - accuracy: 0.9311 - val_loss: 0.4773 - val_accuracy: 0.8160\n",
      "Epoch 8/8\n",
      "83/83 [==============================] - 868s 10s/step - loss: 0.1682 - accuracy: 0.9398 - val_loss: 0.5658 - val_accuracy: 0.8281\n"
     ]
    }
   ],
   "source": [
    "history_1 = model_1.fit(pad_seq, \n",
    "                    y_filtered_converted,\n",
    "                    batch_size=128, \n",
    "                    verbose=1, \n",
    "                    epochs=8,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a39bdc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Embedding(vocab_size, 200, weights = [embedding_matrix], input_length = 1100, trainable = False))\n",
    "\n",
    "model_2.add(Conv1D(256, 3, activation='tanh', padding = 'same'))\n",
    "model_2.add(Conv1D(128, 3, activation='tanh', padding = 'same'))\n",
    "\n",
    "model_2.add(MaxPooling1D(pool_size = 3, strides = 2, padding = 'same'))\n",
    "\n",
    "model_2.add(Dropout(0.5))\n",
    "\n",
    "model_2.add(Bidirectional(LSTM(256, return_sequences = True, kernel_regularizer = keras.regularizers.L2(1e-4))))\n",
    "model_2.add(Bidirectional(LSTM(256, return_sequences = True, kernel_regularizer = keras.regularizers.L2(1e-4))))\n",
    "model_2.add(Bidirectional(LSTM(128)))\n",
    "\n",
    "model_2.add(Dense(10, activation = 'relu'))\n",
    "            \n",
    "model_2.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "model_2.compile(optimizer='adam',loss='binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85c549bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "83/83 [==============================] - 829s 10s/step - loss: 0.6000 - accuracy: 0.7570 - val_loss: 0.4927 - val_accuracy: 0.7883\n",
      "Epoch 2/8\n",
      "83/83 [==============================] - 882s 11s/step - loss: 0.4555 - accuracy: 0.8149 - val_loss: 0.4359 - val_accuracy: 0.8156\n",
      "Epoch 3/8\n",
      "83/83 [==============================] - 910s 11s/step - loss: 0.4180 - accuracy: 0.8285 - val_loss: 0.4128 - val_accuracy: 0.8323\n",
      "Epoch 4/8\n",
      "83/83 [==============================] - 927s 11s/step - loss: 0.3723 - accuracy: 0.8532 - val_loss: 0.4020 - val_accuracy: 0.8270\n",
      "Epoch 5/8\n",
      "83/83 [==============================] - 937s 11s/step - loss: 0.3266 - accuracy: 0.8731 - val_loss: 0.4028 - val_accuracy: 0.8323\n",
      "Epoch 6/8\n",
      "83/83 [==============================] - 940s 11s/step - loss: 0.2942 - accuracy: 0.8867 - val_loss: 0.4383 - val_accuracy: 0.8247\n",
      "Epoch 7/8\n",
      "83/83 [==============================] - 969s 12s/step - loss: 0.2809 - accuracy: 0.8914 - val_loss: 0.4377 - val_accuracy: 0.8077\n",
      "Epoch 8/8\n",
      "83/83 [==============================] - 962s 12s/step - loss: 0.2373 - accuracy: 0.9115 - val_loss: 0.4447 - val_accuracy: 0.8316\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(pad_seq, \n",
    "                    y_filtered_converted,\n",
    "                    batch_size=128, \n",
    "                    verbose=1, \n",
    "                    epochs=8,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc18b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
